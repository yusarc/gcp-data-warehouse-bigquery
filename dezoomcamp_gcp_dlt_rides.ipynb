{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRrm3T7cSZY84j+L2SrdIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusarc/gcp-data-warehouse-bigquery/blob/main/dezoomcamp_gcp_dlt_rides.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dtLhBrBZTR3w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata  # Colab'e özel\n",
        "\n",
        "os.environ[\"DESTINATION__CREDENTIALS\"] = userdata.get(\"GCP_CREDENTIALS\")\n",
        "os.environ[\"BUCKET_URL\"] = \"gs://dezoomcamp_hw3_arcan_2025\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlt[bigquery]\n"
      ],
      "metadata": {
        "id": "ES8-3xplV61M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlt[gs]\n"
      ],
      "metadata": {
        "id": "BHN4qlDdV8nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlt[duckdb]\n"
      ],
      "metadata": {
        "id": "B0ZdrHSAV-KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlt\n",
        "import requests\n",
        "import pandas as pd\n",
        "from dlt.destinations import filesystem\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "_iDeN3ExVM84"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dlt.resource(name=\"rides\", write_disposition=\"replace\")\n",
        "def download_parquet():\n",
        "    prefix = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata\"\n",
        "\n",
        "    for month in range(1, 7):\n",
        "        url = f\"{prefix}_2024-0{month}.parquet\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        df = pd.read_parquet(BytesIO(response.content))\n",
        "\n",
        "        # Her ay için bir batch veri\n",
        "        yield df\n"
      ],
      "metadata": {
        "id": "1QzF4b9JWT9V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"rides_pipeline\",\n",
        "    destination=\"duckdb\",      # önce local test\n",
        "    dataset_name=\"rides_dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "HlotL7fPWXWo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# DuckDB testinde GCP credentials'a ihtiyacımız yok\n",
        "if \"DESTINATION__CREDENTIALS\" in os.environ:\n",
        "    del os.environ[\"DESTINATION__CREDENTIALS\"]\n"
      ],
      "metadata": {
        "id": "kVyclVoxWhzq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_info = pipeline.run(download_parquet)\n",
        "\n",
        "print(load_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pZEelOcXN24",
        "outputId": "8b21a4af-a913-4fad-fa0c-7fb02d5e9e46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline rides_pipeline load step completed in 27.18 seconds\n",
            "1 load package(s) were loaded to destination duckdb and into dataset rides_dataset\n",
            "The duckdb destination used duckdb:////content/rides_pipeline.duckdb location to store data\n",
            "Load package 1770237320.4104617 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
        "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
        "\n",
        "res = conn.sql(\"DESCRIBE\").df()\n",
        "print(res)\n",
        "\n",
        "row_count = conn.sql(\"SELECT count(*) AS row_count FROM rides\").df()\n",
        "print(row_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-2rVzTxXube",
        "outputId": "fd554d27-b256-4160-9d40-ef772f53745d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         database         schema                 name  \\\n",
            "0  rides_pipeline  rides_dataset           _dlt_loads   \n",
            "1  rides_pipeline  rides_dataset  _dlt_pipeline_state   \n",
            "2  rides_pipeline  rides_dataset         _dlt_version   \n",
            "3  rides_pipeline  rides_dataset                rides   \n",
            "\n",
            "                                        column_names  \\\n",
            "0  [load_id, schema_name, status, inserted_at, sc...   \n",
            "1  [version, engine_version, pipeline_name, state...   \n",
            "2  [version, engine_version, inserted_at, schema_...   \n",
            "3  [vendor_id, tpep_pickup_datetime, tpep_dropoff...   \n",
            "\n",
            "                                        column_types  temporary  \n",
            "0  [VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...      False  \n",
            "1  [BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...      False  \n",
            "2  [BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...      False  \n",
            "3  [INTEGER, TIMESTAMP WITH TIME ZONE, TIMESTAMP ...      False  \n",
            "   row_count\n",
            "0   20332093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Daha önce set ettiğimiz değişkeni temizleyelim\n",
        "if \"DESTINATION__CREDENTIALS\" in os.environ:\n",
        "    del os.environ[\"DESTINATION__CREDENTIALS\"]\n"
      ],
      "metadata": {
        "id": "-d4qE0dKX7cE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Service account JSON dosyanın yolu\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/gcs.json\"\n"
      ],
      "metadata": {
        "id": "WaTAP9KyYcpn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bq_pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"rides_pipeline_bq\",\n",
        "    destination=\"bigquery\",\n",
        "    dataset_name=\"rides_dataset\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "amysfnuNYgMw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "# Secret'tan JSON string'i al\n",
        "creds_json = userdata.get(\"GCP_CREDENTIALS\")\n",
        "\n",
        "# JSON string'ini dict'e çevir\n",
        "creds = json.loads(creds_json)\n",
        "\n",
        "creds.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD0K2C6ea5TP",
        "outputId": "9c46d3e9-f3fb-48f9-e06e-dbe0f30528d6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['type', 'project_id', 'private_key_id', 'private_key', 'client_email', 'client_id', 'auth_uri', 'token_uri', 'auth_provider_x509_cert_url', 'client_x509_cert_url', 'universe_domain'])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dlt'nin BigQuery için beklediği env değişkenlerini set ediyoruz\n",
        "os.environ[\"DESTINATION__BIGQUERY__CREDENTIALS__PROJECT_ID\"] = creds[\"project_id\"]\n",
        "os.environ[\"DESTINATION__BIGQUERY__CREDENTIALS__CLIENT_EMAIL\"] = creds[\"client_email\"]\n",
        "os.environ[\"DESTINATION__BIGQUERY__CREDENTIALS__PRIVATE_KEY\"] = creds[\"private_key\"]\n"
      ],
      "metadata": {
        "id": "I3G5pVK7bFPg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bq_pipeline = dlt.pipeline(\n",
        "    pipeline_name=\"rides_pipeline_bq\",\n",
        "    destination=\"bigquery\",\n",
        "    dataset_name=\"rides_dataset\",\n",
        ")\n",
        "\n",
        "bq_load_info = bq_pipeline.run(download_parquet)\n",
        "\n",
        "print(bq_load_info)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0B54_kcbJ9D",
        "outputId": "ab78573e-66ac-43db-c1a5-279a4c894c45"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline rides_pipeline_bq load step completed in 36.17 seconds\n",
            "1 load package(s) were loaded to destination bigquery and into dataset rides_dataset\n",
            "The bigquery destination used bigquery@gcp-data-warehouse-486419.iam.gserviceaccount.com@gcp-data-warehouse-486419 location to store data\n",
            "Load package 1770238301.5603597 is LOADED and contains no failed jobs\n"
          ]
        }
      ]
    }
  ]
}